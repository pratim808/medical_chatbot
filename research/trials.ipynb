{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Chatbot\\medical_chatbot\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Manas\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "DATA_PATH = r'G:\\Chatbot\\data'\n",
    "DB_FAISS_PATH = r'G:\\Chatbot\\data\\vector'\n",
    "\n",
    "# Create vector database\n",
    "\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(DATA_PATH,\n",
    "                             glob='*.pdf',\n",
    "                             loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                                   chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    db.save_local(DB_FAISS_PATH)\n",
    "\n",
    "\n",
    "create_vector_db()  # Call the function directly in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FAISS_PATH = r'G:\\Chatbot\\data\\vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS vector database\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                   model_kwargs={'device': 'cpu'})\n",
    "db = FAISS.load_local(DB_FAISS_PATH, embeddings,\n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"2bd5fd9f-2c56-42f9-aa1b-037960262fff\"\n",
    "PINECONE_API_ENV = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cpu'}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch = Pinecone.from_texts(\n",
    "    [t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content=\"GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\\nAllergic rhinitis is commonly triggered by\\nexposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\\nThe presence of an allergen causes the\\nbody's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\\nIgE molecules attach to mast\\ncells, which contain histamine.HistaminePollen grains\\nLymphocyte\\nFIRST EXPOSURE\", metadata={}), Document(page_content='allergens are the following:\\n• plant pollens\\n• animal fur and dander\\n• body parts from house mites (microscopic creatures\\nfound in all houses)\\n• house dust• mold spores• cigarette smoke• solvents• cleaners\\nCommon food allergens include the following:\\n• nuts, especially peanuts, walnuts, and brazil nuts\\n• fish, mollusks, and shellfish• eggs• wheat• milk• food additives and preservatives\\nThe following types of drugs commonly cause aller-\\ngic reactions:\\n• penicillin or other antibiotics', metadata={}), Document(page_content='itchy, scratchy nose, eyes, and throat common in aller-gic rhinitis.\\nThe number of possible airborne allergens is enor-', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# If we already have an index we can load it like this\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Document(metadata={'source': 'G:\\\\Chatbot\\\\data\\\\Medical_book.pdf', 'page': 131}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2118\\nAllergies\\nGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 118'), Document(metadata={'source': 'G:\\\\Chatbot\\\\data\\\\Medical_book.pdf', 'page': 134}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 121\\nAllergies\\nGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 121'), Document(metadata={'source': 'G:\\\\Chatbot\\\\data\\\\Medical_book.pdf', 'page': 127}, page_content='ders Co., 1993.\\nLawlor, G. J. Jr., T. J. Fischer, and D. C. Adelman. Manual of\\nAllergy and Immunology.Boston: Little, Brown and Co.,\\n1995.\\nNovick, N. L. You Can Do Something About Your Allergies.\\nNew York: Macmillan, 1994.\\nWeil, A. Natural Health, Natural Medicine: A Comprehensive\\nManual for Wellness and Self-Care.New York: Houghton\\nMifflin, 1995.\\nRichard Robinson\\nAllergies\\nDefinition\\nAllergies are abnormal reactions of the immune sys-\\ntem that occur in response to otherwise harmless sub-')]\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "query = \"What are Allergies\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Result:\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "# import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template,\n",
    "                        input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model=r\"G:\\Chatbot\\model\\llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={'max_new_tokens': 512,\n",
    "                            'temperature': 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manas\\AppData\\Local\\Temp\\ipykernel_7500\\1781939318.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa({\"query\": user_input})\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt:\")\n",
    "    result = qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FAISS_PATH = r'G:\\Chatbot\\data\\vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store DB Is Ready\n",
      "Response time : 0.859375\n",
      "Allergies are abnormal reactions of the immune system that occur in response to otherwise harmless substances.\n",
      "\n",
      "Document Similarity Search:\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2118\n",
      "Allergies\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 118\n",
      "--------------------------------\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2 121\n",
      "Allergies\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 121\n",
      "--------------------------------\n",
      "ders Co., 1993.\n",
      "Lawlor, G. J. Jr., T. J. Fischer, and D. C. Adelman. Manual of\n",
      "Allergy and Immunology.Boston: Little, Brown and Co.,\n",
      "1995.\n",
      "Novick, N. L. You Can Do Something About Your Allergies.\n",
      "New York: Macmillan, 1994.\n",
      "Weil, A. Natural Health, Natural Medicine: A Comprehensive\n",
      "Manual for Wellness and Self-Care.New York: Houghton\n",
      "Mifflin, 1995.\n",
      "Richard Robinson\n",
      "Allergies\n",
      "Definition\n",
      "Allergies are abnormal reactions of the immune sys-\n",
      "tem that occur in response to otherwise harmless sub-\n",
      "--------------------------------\n",
      "to commonly encountered environmental substances.\n",
      "Purpose\n",
      "Allergy is a reaction of the immune system. Nor-\n",
      "mally, the immune system responds to foreign microor-\n",
      "ganisms and particles, like pollen or dust, by producing\n",
      "specific proteins called antibodies that are capable of\n",
      "binding to identifying molecules, or antigens, on the\n",
      "foreign organisms. This reaction between antibody and\n",
      "antigen sets off a series of reactions designed to protect\n",
      "the body from infection. Sometimes, this same series of\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "#\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "# Load the FAISS vector database\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                   model_kwargs={'device': 'cpu'})\n",
    "db = FAISS.load_local(DB_FAISS_PATH, embeddings,\n",
    "                      allow_dangerous_deserialization=True)\n",
    "load_dotenv()\n",
    "# download embedding model\n",
    "\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Load the GROQ and OpenAI API keys\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = ('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')\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(groq_api_key=groq_api_key,\n",
    "               model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Context: {context}\n",
    "Question: {input} \n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "'''def vector_embedding():\n",
    "    \"\"\"Embeds the documents and stores them in a FAISS vector store.\"\"\"\n",
    "\n",
    "    #embeddings = OpenAIEmbeddings()\n",
    "    embeddings= HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    loader = PyPDFDirectoryLoader(\"/kaggle/input/book-pdf-1\")  # Data Ingestion\n",
    "    docs = loader.load()  # Document Loading\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)  # Chunk Creation\n",
    "    final_documents = text_splitter.split_documents(docs[:20])  # Splitting\n",
    "    vectors = FAISS.from_documents(final_documents, embeddings)  # Vector OpenAI embeddings\n",
    "    return vectors'''\n",
    "\n",
    "# Get user input\n",
    "prompt1 = input(\"Enter Your Question From Documents: \")\n",
    "\n",
    "# Embed the documents\n",
    "vectors = db\n",
    "print(\"Vector Store DB Is Ready\")\n",
    "\n",
    "\n",
    "if prompt1:\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retriever = vectors.as_retriever()\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    start = time.process_time()\n",
    "    response = retrieval_chain.invoke({'input': prompt1})\n",
    "    print(\"Response time :\", time.process_time() - start)\n",
    "    print(response['answer'])\n",
    "\n",
    "    # Print similar documents\n",
    "    print(\"\\nDocument Similarity Search:\")\n",
    "    for i, doc in enumerate(response[\"context\"]):\n",
    "        print(doc.page_content)\n",
    "        print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
